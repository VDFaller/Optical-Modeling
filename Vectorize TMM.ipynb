{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy as sp\n",
    "import tmm_core as tmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Material:\n",
    "    def __init__(self, path, name, wavelengths):\n",
    "        f = pd.read_csv(path)\n",
    "        wv_raw = np.array(f.wv)\n",
    "        nc = np.array(f.n+f.k*1j)  # complex refractive index\n",
    "        self.name = name\n",
    "        self.f = interp1d(wv_raw, nc, kind='cubic')\n",
    "        self.min_wv = min(wv_raw)\n",
    "        self.max_wv = max(wv_raw)\n",
    "        self.df = pd.Series(data=nc, index=wv_raw, name=name)\n",
    "        # self.df = self.df.reindex(wavelengths)\n",
    "        # self.df = self.df.interpolate('spline', order=3)\n",
    "        self.interp(wavelengths)\n",
    "\n",
    "    def interp(self, wavelengths):\n",
    "        wavelengths = wavelengths[np.nonzero(np.logical_and(wavelengths > self.min_wv, wavelengths < self.max_wv))]\n",
    "        nc = self.f(wavelengths)\n",
    "        self.df = pd.DataFrame(nc,wavelengths, [self.name])\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.wavelength = np.arange(300, 1700, 1)\n",
    "        self.increment = .2\n",
    "        self.index_array = np.array([])\n",
    "        self.materials = []\n",
    "        self.mat_df = pd.DataFrame([], self.wavelength)\n",
    "        self.data = {}\n",
    "        self.thicknesses = [sp.inf, 0, sp.inf]\n",
    "        self.layers = []\n",
    "\n",
    "        self.add_material(\"TCO\", './Materials/Semiconductor/TCO.csv')\n",
    "        self.add_material(\"CdSe\", './Materials/Semiconductor/CdSe.csv')\n",
    "        self.add_material(\"CdTe\", './Materials/Semiconductor/CdTe.csv')\n",
    "        self.add_material(\"Air\", './Materials/Semiconductor/Air.csv')\n",
    "        self.add_material(\"BK7\", './Materials/Dielectric/BK7.csv')\n",
    "        self.add_material(\"SLG\", './Materials/Dielectric/SLG.csv')\n",
    "        self.add_material(\"SS TCO\", './Materials/Dielectric/Sunnyside TCO.csv')\n",
    "        self.add_material(\"SiO2\", './Materials/Dielectric/SiO2-Jaw.csv')\n",
    "        \n",
    "    def add_material(self, film, path):\n",
    "        if film not in self.mat_df:\n",
    "            mat = Material(path, film, self.wavelength)\n",
    "            self.materials.append(mat)\n",
    "            self.mat_df = self.mat_df.join(mat.df)\n",
    "\n",
    "    def set_wavelength(self, low, high, interval):\n",
    "        self.wavelength = np.arange(low, high, interval)\n",
    "        df = self.mat_df.reindex(self.wavelength)\n",
    "        df = df.interpolate('spline', order=3)\n",
    "        self.mat_df = df\n",
    "\n",
    "    def better_bruggeman(self, n1, n2, percent_included):\n",
    "        p = n1/n2\n",
    "        b = .25*((3*percent_included-1)*(1/p-p)+p)\n",
    "        z = b + (b**2 + .5)**0.5\n",
    "        e = z*n1*n2\n",
    "        return {\"e\": e, \"n\": e**0.5, 'conc': percent_included, \"n1\": n1, 'n2': n2}\n",
    "\n",
    "    def brug_transform(self, df, layer, incl, percent):\n",
    "        p = df[layer]/incl\n",
    "        b = .25*((3*percent-1)*(1/p-p)+p)\n",
    "        z = b + (b**2 + .5)**0.5\n",
    "        e = z*df[layer]*incl\n",
    "        n = e**.5\n",
    "        df[layer] = n\n",
    "    \n",
    "    def run(self, wavelengths, void_percent):\n",
    "        mat = self.mat_df.ix[wavelengths]\n",
    "        mat = mat[self.layers]\n",
    "        self.brug_transform(mat, self.layers[1], mat['Air'], void_percent)\n",
    "        self.index_array = np.array(mat)\n",
    "        theta0 = 45*sp.pi/180\n",
    "        self.data = tmm.unpolarized_RT(self.index_array, self.thicknesses, theta0, wavelengths)\n",
    "        \n",
    "    def normalized(a, axis=-1, order=2):\n",
    "        l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "        l2[l2==0] = 1\n",
    "        return a / np.expand_dims(l2, axis)\n",
    "    \n",
    "    def get_R(self, wavelengths, thickness, void_percent):\n",
    "        self.thicknesses[1] = thickness\n",
    "        self.run(wavelengths, void_percent) \n",
    "        R = self.data['R']\n",
    "        R -= min(R)\n",
    "        R /= max(R)\n",
    "        return R\n",
    "        \n",
    "    def RMSE(self, thickness, data):\n",
    "        df = pd.DataFrame(data)\n",
    "        self.get_R(thickness)\n",
    "        model = pd.DataFrame(self.data['R'], index=self.wavelength)\n",
    "        df = df.join(model, how='inner')\n",
    "        n = len(df.index)\n",
    "        return (sum((data-model)**2)/n)**0.5\n",
    "    \n",
    "    def norm(self, wavelength):\n",
    "        df = self.df.ix[wavelength]\n",
    "        df = df - df.min()\n",
    "        df = df / df.max()\n",
    "        return df\n",
    "    \n",
    "    def fit(self, wv, data):\n",
    "        mod = lmfit.Model(self.get_R, ['wavelengths'], ['thickness','void_percent'])\n",
    "        mod.set_param_hint('thickness', value = 120, min=50, max=250)\n",
    "        mod.set_param_hint('void_percent', value = .15, min=0, max=1)\n",
    "        \n",
    "        weight = np.array(data.weight.ix[wv])\n",
    "        R = data.series.ix[wv]\n",
    "        result = mod.fit(R, wavelengths=wv, weights=weight)\n",
    "        \n",
    "        RMSE = (sp.sum(result.residual**2)/(result.residual.size-2))**0.5\n",
    "        bf_values = result.best_values\n",
    "        bf_str = 'thk: ' + str(round(bf_values['thickness'])) +\", Void %: \" + str(round(bf_values['void_percent']*100, 2))\n",
    "        txt_spot = wv.min()-200 + (wv.max()-wv.min()) / 2\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.text(txt_spot, .9, \"RMSE: \"+str(round(RMSE, 3)))\n",
    "        ax.text(txt_spot, .85, bf_str)\n",
    "        result.plot_fit(yerr=np.zeros(len(data.series.index)), data_kws ={'marker':'+'})\n",
    "\n",
    "        plt.show()\n",
    "        print(result.fit_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "For information see the docstring of each function, and also see manual.pdf\n",
    "\n",
    "The most two important functions are:\n",
    "\n",
    "coh_tmm(...) -- the transfer-matrix-method calculation in the coherent\n",
    "case (i.e. thin films)\n",
    "\n",
    "inc_tmm(...) -- the transfer-matrix-method calculation in the incoherent\n",
    "case (i.e. films tens or hundreds of wavelengths thick, or whose\n",
    "thickness is not very uniform.\n",
    "\n",
    "These functions are all imported into the main package (tmm) namespace,\n",
    "so you can call them with tmm.coh_tmm(...) etc.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "from numpy import cos, inf, zeros, array, exp, conj, nan, isnan\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "EPSILON = sys.float_info.epsilon # typical floating-point calculation error\n",
    "\n",
    "def make_2x2_array(a, b, c, d, dtype=float):\n",
    "    \"\"\"\n",
    "    Makes a 2x2 numpy array of [[a,b],[c,d]]\n",
    "    \n",
    "    Same as \"numpy.array([[a,b],[c,d]], dtype=float)\", but ten times faster\n",
    "    \"\"\"\n",
    "    my_array = np.empty((2,2),dtype=dtype)\n",
    "    my_array[0,0] = a\n",
    "    my_array[0,1] = b\n",
    "    my_array[1,0] = c\n",
    "    my_array[1,1] = d\n",
    "    return my_array\n",
    "\n",
    "def snell(n_1,n_2,th_1):\n",
    "    \"\"\"\n",
    "    return angle theta in layer 2 with refractive index n_2, assuming\n",
    "    it has angle th_1 in layer with refractive index n_1. Use Snell's law. Note\n",
    "    that \"angles\" may be complex!!\n",
    "    \"\"\"\n",
    "    #Important that the arcsin here is scipy.arcsin, not numpy.arcsin!! (They\n",
    "    #give different results e.g. for arcsin(2).)\n",
    "    #Use real_if_close because e.g. arcsin(2 + 1e-17j) is very different from\n",
    "    #arcsin(2) due to branch cut\n",
    "    return sp.arcsin(np.real_if_close(n_1*np.sin(th_1) / n_2))\n",
    "\n",
    "def list_snell(n_list,th_0):\n",
    "    \"\"\"\n",
    "    return list of angle theta in each layer based on angle th_0 in layer 0,\n",
    "    using Snell's law. n_list is index of refraction of each layer. Note that\n",
    "    \"angles\" may be complex!!\n",
    "    \"\"\"\n",
    "    #Important that the arcsin here is scipy.arcsin, not numpy.arcsin!! (They\n",
    "    #give different results e.g. for arcsin(2).)\n",
    "    #Use real_if_close because e.g. arcsin(2 + 1e-17j) is very different from\n",
    "    #arcsin(2) due to branch cut\n",
    "    return sp.arcsin(np.real_if_close((n_list[:,0]*np.sin(th_0))[:,None] / n_list))\n",
    "\n",
    "\n",
    "def interface_r(polarization, n_i, n_f, th_i, th_f):\n",
    "    \"\"\"\n",
    "    reflection amplitude (from Fresnel equations)\n",
    "\n",
    "    polarization is either \"s\" or \"p\" for polarization\n",
    "\n",
    "    n_i, n_f are (complex) refractive index for incident and final\n",
    "\n",
    "    th_i, th_f are (complex) propegation angle for incident and final\n",
    "    (in radians, where 0=normal). \"th\" stands for \"theta\".\n",
    "    \"\"\"\n",
    "    if polarization == 's':\n",
    "        #return 2 * n_i * cos(th_i) / (n_i * cos(th_i) + n_f * cos(th_f))\n",
    "        return ((n_i * cos(th_i) - n_f * cos(th_f)) /\n",
    "                (n_i * cos(th_i) + n_f * cos(th_f)))\n",
    "    elif polarization == 'p':\n",
    "        return ((n_f * cos(th_i) - n_i * cos(th_f)) /\n",
    "                (n_f * cos(th_i) + n_i * cos(th_f)))\n",
    "    else:\n",
    "        raise ValueError(\"Polarization must be 's' or 'p'\")\n",
    "\n",
    "def interface_t(polarization, n_i, n_f, th_i, th_f):\n",
    "    \"\"\"\n",
    "    transmission amplitude (frem Fresnel equations)\n",
    "\n",
    "    polarization is either \"s\" or \"p\" for polarization\n",
    "\n",
    "    n_i, n_f are (complex) refractive index for incident and final\n",
    "\n",
    "    th_i, th_f are (complex) propegation angle for incident and final\n",
    "    (in radians, where 0=normal). \"th\" stands for \"theta\".\n",
    "    \"\"\"\n",
    "    if polarization == 's':\n",
    "        return 2 * n_i * cos(th_i) / (n_i * cos(th_i) + n_f * cos(th_f))\n",
    "    elif polarization == 'p':\n",
    "        return 2 * n_i * cos(th_i) / (n_f * cos(th_i) + n_i * cos(th_f))\n",
    "    else:\n",
    "        raise ValueError(\"Polarization must be 's' or 'p'\")\n",
    "\n",
    "def R_from_r(r):\n",
    "    \"\"\"\n",
    "    Calculate reflected power R, starting with reflection amplitude r.\n",
    "    \"\"\"\n",
    "    return abs(r)**2\n",
    "\n",
    "def T_from_t(pol, t, n_i, n_f, th_i, th_f):\n",
    "    \"\"\"\n",
    "    Calculate transmitted power T, starting with transmission amplitude t.\n",
    "\n",
    "    n_i,n_f are refractive indices of incident and final medium.\n",
    "\n",
    "    th_i, th_f are (complex) propegation angles through incident & final medium\n",
    "    (in radians, where 0=normal). \"th\" stands for \"theta\".\n",
    "\n",
    "    In the case that n_i,n_f,th_i,th_f are real, formulas simplify to\n",
    "    T=|t|^2 * (n_f cos(th_f)) / (n_i cos(th_i)).\n",
    "\n",
    "    See manual for discussion of formulas\n",
    "    \"\"\"\n",
    "    if(pol=='s'):\n",
    "        return abs(t**2) * (((n_f*cos(th_f)).real) / (n_i*cos(th_i)).real)\n",
    "    elif(pol=='p'):\n",
    "        return abs(t**2) * (((n_f*conj(cos(th_f))).real) /\n",
    "                                (n_i*conj(cos(th_i))).real)\n",
    "    else:\n",
    "        raise ValueError(\"Polarization must be 's' or 'p'\")\n",
    "\n",
    "def power_entering_from_r(pol, r, n_i, th_i):\n",
    "    \"\"\"\n",
    "    Calculate the power entering the first interface of the stack, starting with\n",
    "    reflection amplitude r. Normally this equals 1-R, but in the unusual case\n",
    "    that n_i is not real, it can be a bit different than 1-R. See manual.\n",
    "\n",
    "    n_i is refractive index of incident medium.\n",
    "\n",
    "    th_i is (complex) propegation angle through incident medium\n",
    "    (in radians, where 0=normal). \"th\" stands for \"theta\".\n",
    "    \"\"\"\n",
    "    if(pol=='s'):\n",
    "        return ((n_i*cos(th_i)*(1+conj(r))*(1-r)).real\n",
    "                     / (n_i*cos(th_i)).real)\n",
    "    elif(pol=='p'):\n",
    "        return ((n_i*conj(cos(th_i))*(1+r)*(1-conj(r))).real\n",
    "                      / (n_i*conj(cos(th_i))).real)\n",
    "    else:\n",
    "        raise ValueError(\"Polarization must be 's' or 'p'\")\n",
    "\n",
    "def interface_R(polarization, n_i, n_f, th_i, th_f):\n",
    "    \"\"\"\n",
    "    Fraction of light intensity reflected at an interface.\n",
    "    \"\"\"\n",
    "    r = interface_r(polarization,n_i,n_f,th_i,th_f)\n",
    "    return R_from_r(r)\n",
    "\n",
    "def interface_T(polarization, n_i, n_f, th_i, th_f):\n",
    "    \"\"\"\n",
    "    Fraction of light intensity transmitted at an interface.\n",
    "    \"\"\"\n",
    "    t = interface_t(polarization,n_i,n_f,th_i,th_f)\n",
    "    return T_from_t(polarization,t,n_i,n_f,th_i,th_f)\n",
    "\n",
    "def coh_tmm(pol, n_list, d_list, th_0, lam_vac):\n",
    "    \"\"\"\n",
    "    Main \"coherent transfer matrix method\" calc. Given parameters of a stack,\n",
    "    calculates everything you could ever want to know about how light\n",
    "    propagates in it. (If performance is an issue, you can delete some of the\n",
    "    calculations without affecting the rest.)\n",
    "    \n",
    "    pol is light polarization, \"s\" or \"p\".\n",
    "    \n",
    "    n_list is the list of refractive indices, in the order that the light would\n",
    "    pass through them. The 0'th element of the list should be the semi-infinite\n",
    "    medium from which the light enters, the last element should be the semi-\n",
    "    infinite medium to which the light exits (if any exits).\n",
    "    \n",
    "    th_0 is the angle of incidence: 0 for normal, pi/2 for glancing.\n",
    "    Remember, for a dissipative incoming medium (n_list[0] is not real), th_0\n",
    "    should be complex so that n0 sin(th0) is real (intensity is constant as\n",
    "    a function of lateral position).\n",
    "    \n",
    "    d_list is the list of layer thicknesses (front to back). Should correspond\n",
    "    one-to-one with elements of n_list. First and last elements should be \"inf\".\n",
    "    \n",
    "    lam_vac is vacuum wavelength of the light.\n",
    "    \n",
    "    Outputs the following as a dictionary (see manual for details)\n",
    "    \n",
    "    * r--reflection amplitude\n",
    "    * t--transmission amplitude\n",
    "    * R--reflected wave power (as fraction of incident)\n",
    "    * T--transmitted wave power (as fraction of incident)\n",
    "    * power_entering--Power entering the first layer, usually (but not always)\n",
    "      equal to 1-R (see manual).\n",
    "    * vw_list-- n'th element is [v_n,w_n], the forward- and backward-traveling\n",
    "      amplitudes, respectively, in the n'th medium just after interface with\n",
    "      (n-1)st medium.\n",
    "    * kz_list--normal component of complex angular wavenumber for\n",
    "      forward-traveling wave in each layer.\n",
    "    * th_list--(complex) propagation angle (in radians) in each layer\n",
    "    * pol, n_list, d_list, th_0, lam_vac--same as input\n",
    "\n",
    "    \"\"\"\n",
    "    #convert lists to numpy arrays if they're not already.\n",
    "    #n_list=array(n_list)\n",
    "    d_list=array(d_list,dtype=float)\n",
    "\n",
    "    #input tests\n",
    "    #if ((hasattr(lam_vac, 'size') and lam_vac.size > 1)\n",
    "    #      or (hasattr(th_0, 'size') and th_0.size > 1)):\n",
    "    #    raise ValueError('This function is not vectorized; you need to run one '\n",
    "    #                     'calculation at a time (1 wavelength, 1 angle, etc.)')\n",
    "    #if (n_list.ndim != 1) or (d_list.ndim != 1) or (n_list.size != d_list.size):\n",
    "    #    raise ValueError(\"Problem with n_list or d_list!\")\n",
    "    if (d_list[0] != inf) or (d_list[-1] != inf):\n",
    "        raise ValueError('d_list must start and end with inf!')\n",
    "    #if abs((n_list[0]*np.sin(th_0)).imag) > 100*EPSILON:\n",
    "        #raise ValueError('Error in n0 or th0!')\n",
    "    num_layers = n_list.shape[1]\n",
    "    n_wv = n_list.shape[0]\n",
    "\n",
    "    #th_list is a list with, for each layer, the angle that the light travels\n",
    "    #through the layer. Computed with Snell's law. Note that the \"angles\" may be\n",
    "    #complex!\n",
    "    th_list = list_snell(n_list,th_0)\n",
    "\n",
    "    #kz is the z-component of (complex) angular wavevector for forward-moving\n",
    "    #wave. Positive imaginary part means decaying.\n",
    "    kz_list = (2 * np.pi * n_list * np.cos(th_list)) / lam_vac[:, None]\n",
    "\n",
    "    #delta is the total phase accrued by traveling through a given layer.\n",
    "    #ignore warning about inf multiplication\n",
    "    olderr = sp.seterr(invalid= 'ignore')\n",
    "    delta = kz_list * d_list\n",
    "    sp.seterr(**olderr)\n",
    "    \n",
    "    # For a very opaque layer, reset delta to avoid divide-by-0 and similar\n",
    "    # errors. The criterion imag(delta) > 35 corresponds to single-pass\n",
    "    # transmission < 1e-30 --- small enough that the exact value doesn't\n",
    "    # matter.\n",
    "    if (delta.imag>35).any():\n",
    "        delta.imag[delta.imag>35]=35\n",
    "        if 'opacity_warning' not in globals():\n",
    "            global opacity_warning\n",
    "            opacity_warning = True\n",
    "            print(\"Warning: Layers that are almost perfectly opaque \"\n",
    "                  \"are modified to be slightly transmissive, \"\n",
    "                  \"allowing 1 photon in 10^30 to pass through. It's \"\n",
    "                  \"for numerical stability. This warning will not \"\n",
    "                  \"be shown again.\")\n",
    "    \n",
    "    #t_list[i,j] and r_list[i,j] are transmission and reflection amplitudes,\n",
    "    #respectively, coming from i, going to j. Only need to calculate this when\n",
    "    #j=i+1. (2D array is overkill but helps avoid confusion.)\n",
    "    #t_list = zeros((num_layers,num_layers),dtype=complex)\n",
    "    #r_list = zeros((num_layers,num_layers),dtype=complex)\n",
    "    t_list = np.zeros((n_wv,num_layers),dtype=complex)\n",
    "    r_list = np.zeros((n_wv,num_layers),dtype=complex)\n",
    "    for i in range(num_layers-1):\n",
    "        t_list[:, i] = interface_t(pol, n_list[:,i], n_list[:,i+1], th_list[:,i], th_list[:,i+1])\n",
    "        r_list[:, i] = interface_r(pol, n_list[:,i], n_list[:,i+1], th_list[:,i], th_list[:,i+1])\n",
    "    #At the interface between the (n-1)st and nth material, let v_n be the\n",
    "    #amplitude of the wave on the nth side heading forwards (away from the\n",
    "    #boundary), and let w_n be the amplitude on the nth side heading backwards\n",
    "    #(towards the boundary). Then (v_n,w_n) = M_n (v_{n+1},w_{n+1}). M_n is\n",
    "    #M_list[n]. M_0 and M_{num_layers-1} are not defined.\n",
    "    #My M is a bit different than Sernelius's, but Mtilde is the same.\n",
    "    M1 = np.array([[exp(-1j*delta[:,i]), np.zeros((n_wv))], [np.zeros((n_wv)), exp(1j*delta[:,i])]], dtype=complex).T\n",
    "    M2 = np.array([[np.ones((n_wv)), r_list[:,i]], [r_list[:,i], np.ones((n_wv))]], dtype=complex).T\n",
    "    Mtilde = np.zeros((n_wv,2,2), dtype=complex)\n",
    "    Mtilde[:] = np.identity(2, dtype=complex)\n",
    "    M1[:,0][:,0] = exp(-1j*delta[:,i])\n",
    "    M1[:,1][:,1] = exp(1j*delta[:,i])\n",
    "    # Mtilde = np.identity(2, dtype=complex)\n",
    "    for i in range(1,num_layers-1):\n",
    "        M_list = (1/t_list[:,i]).reshape(n_wv,1,1) * np.einsum('ijk,ikl->ijl',\n",
    "            np.array([[exp(-1j*delta[:,i]), np.zeros((n_wv))], [np.zeros((n_wv)), exp(1j*delta[:,i])]], dtype=complex).T,\n",
    "            np.array([[np.ones((n_wv)), r_list[:,i]], [r_list[:,i], np.ones((n_wv))]], dtype=complex).T\n",
    "        )\n",
    "        Mtilde = np.einsum('ijk,ikl->ijl',Mtilde,M_list)\n",
    "        \n",
    "    Mtilde = np.einsum('ijk,ikl->ijl',np.array([[np.ones((n_wv)), r_list[:,i]], [r_list[:,i], np.ones((n_wv))]], dtype=complex).T/t_list[:,0].reshape(n_wv,1,1), Mtilde)\n",
    "\n",
    "    #Net complex transmission and reflection amplitudes\n",
    "    r=Mtilde[:,1,0]/Mtilde[:,0,0]\n",
    "    t=1/Mtilde[:,0,0]\n",
    "\n",
    "    #vw_list[n] = [v_n, w_n]. v_0 and w_0 are undefined because the 0th medium\n",
    "    #has no left interface.\n",
    "    #===========================================================================\n",
    "    # vw_list=zeros((num_layers,2), dtype=complex)\n",
    "    # vw = array([[t],np.zeros((n_wv))])\n",
    "    # vw_list[-1,:] = np.transpose(vw)\n",
    "    # for i in range(num_layers-2,0,-1):\n",
    "    #     vw = np.dot(M_list[i], vw)\n",
    "    #     vw_list[i,:] = np.transpose(vw)\n",
    "    #===========================================================================\n",
    "\n",
    "    #Net transmitted and reflected power, as a proportion of the incoming light\n",
    "    #power.\n",
    "    R = R_from_r(r)\n",
    "    T = T_from_t(pol, t, n_list[:,0], n_list[:,-1], th_list[:,0], th_list[:,-1])\n",
    "    #===========================================================================\n",
    "    # power_entering = power_entering_from_r(\n",
    "    #                             pol, r, n_list[0], th_0)\n",
    "    #===========================================================================\n",
    "\n",
    "    return {'r': r, 't': t, 'R': R, 'T': T, \n",
    "            #===================================================================\n",
    "            # 'power_entering': power_entering,'vw_list': vw_list, \n",
    "            #===================================================================\n",
    "            'kz_list': kz_list, 'th_list': th_list,\n",
    "            't_list': t_list, 'r_list': r_list,\n",
    "            'pol': pol, 'n_list': n_list, 'd_list': d_list, 'th_0': th_0,\n",
    "            'lam_vac':lam_vac}\n",
    "\n",
    "def coh_tmm_reverse(pol, n_list, d_list, th_0, lam_vac):\n",
    "    \"\"\"\n",
    "    Reverses the order of the stack then runs coh_tmm.\n",
    "    \"\"\"\n",
    "    th_f = snell(n_list[0],n_list[-1],th_0)\n",
    "    return coh_tmm(pol,n_list[::-1],d_list[::-1],th_f,lam_vac)\n",
    "\n",
    "def ellips(n_list, d_list, th_0, lam_vac):\n",
    "    \"\"\"\n",
    "    Calculates ellipsometric parameters, in radians.\n",
    "\n",
    "    Warning: Conventions differ. You may need to subtract pi/2 or whatever.\n",
    "    \"\"\"\n",
    "\n",
    "    s_data=coh_tmm('s',n_list, d_list, th_0, lam_vac)\n",
    "    p_data=coh_tmm('p',n_list, d_list, th_0, lam_vac)\n",
    "    rs = s_data['r']\n",
    "    rp = p_data['r']\n",
    "    return {'psi': np.arctan(abs(rp/rs)), 'Delta': np.angle(-rp/rs)}\n",
    "\n",
    "def unpolarized_RT(n_list, d_list, th_0, lam_vac):\n",
    "    \"\"\"\n",
    "    Calculates reflected and transmitted power for unpolarized light.\n",
    "    \"\"\"\n",
    "\n",
    "    s_data = coh_tmm('s',n_list, d_list, th_0, lam_vac)\n",
    "    p_data = coh_tmm('p',n_list, d_list, th_0, lam_vac)\n",
    "    R = (s_data['R'] + p_data['R']) / 2.\n",
    "    T = (s_data['T'] + p_data['T']) / 2.\n",
    "    return {'R': R, 'T': T}\n",
    "\n",
    "def position_resolved(layer, dist, coh_tmm_data):\n",
    "    \"\"\"\n",
    "    Starting with output of coh_tmm(), calculate the Poynting vector\n",
    "    and absorbed energy density a distance \"dist\" into layer number \"layer\"\n",
    "    \"\"\"\n",
    "    vw = coh_tmm_data['vw_list'][layer]\n",
    "    kz = coh_tmm_data['kz_list'][layer]\n",
    "    th = coh_tmm_data['th_list'][layer]\n",
    "    n = coh_tmm_data['n_list'][layer]\n",
    "    n_0 = coh_tmm_data['n_list'][0]\n",
    "    th_0 = coh_tmm_data['th_0']\n",
    "    pol = coh_tmm_data['pol']\n",
    "\n",
    "    #amplitude of forward-moving wave is Ef, backwards is Eb\n",
    "    Ef = vw[0] * exp(1j * kz * dist)\n",
    "    Eb = vw[1] * exp(-1j * kz * dist)\n",
    "\n",
    "    #Poynting vector\n",
    "    if(pol=='s'):\n",
    "        poyn = ((n*cos(th)*conj(Ef+Eb)*(Ef-Eb)).real) / (n_0*cos(th_0)).real\n",
    "    elif(pol=='p'):\n",
    "        poyn = (((n*conj(cos(th))*(Ef+Eb)*conj(Ef-Eb)).real)\n",
    "                    / (n_0*conj(cos(th_0))).real)\n",
    "\n",
    "    #absorbed energy density\n",
    "    if(pol=='s'):\n",
    "        absor = (n*cos(th)*kz*abs(Ef+Eb)**2).imag / (n_0*cos(th_0)).real\n",
    "    elif(pol=='p'):\n",
    "        absor = (n*conj(cos(th))*\n",
    "                 (kz*abs(Ef-Eb)**2-conj(kz)*abs(Ef+Eb)**2)\n",
    "                ).imag / (n_0*conj(cos(th_0))).real\n",
    "    return({'poyn':poyn, 'absor':absor})\n",
    "\n",
    "def find_in_structure(d_list,dist):\n",
    "    \"\"\"\n",
    "    d_list is list of thicknesses of layers, all of which are finite.\n",
    "\n",
    "    dist is the distance from the front of the whole multilayer structure\n",
    "    (i.e., from the start of layer 0.)\n",
    "\n",
    "    Function returns [layer,z], where:\n",
    "\n",
    "    layer is what number layer you're at.\n",
    "    (For large enough dist, layer = len(d_list), even though d_list[layer]\n",
    "    doesn't exist in that case.\n",
    "\n",
    "    z is the distance into that layer.\n",
    "    \"\"\"\n",
    "    if sum(d_list) == inf:\n",
    "        raise ValueError('This function expects finite arguments')\n",
    "    layer=0\n",
    "    while (layer < len(d_list)) and (dist >= d_list[layer]):\n",
    "        dist -= d_list[layer]\n",
    "        layer += 1\n",
    "    return [layer,dist]\n",
    "\n",
    "def find_in_structure_with_inf(d_list,dist):\n",
    "    \"\"\"\n",
    "    d_list is list of thicknesses of layers [inf, blah, blah, ..., blah, inf]\n",
    "\n",
    "    dist is the distance from the front of the whole multilayer structure\n",
    "    (i.e., frcom the start of layer 1.)\n",
    "\n",
    "    Function returns [layer,z], where:\n",
    "\n",
    "    layer is what number layer you're at,\n",
    "\n",
    "    z is the distance into that layer.\n",
    "    \"\"\"\n",
    "    [layer,dist] = find_in_structure(d_list[1:-1],dist)\n",
    "    return [layer+1,dist]\n",
    "\n",
    "def layer_starts(d_list):\n",
    "    \"\"\"\n",
    "    Gives the location of the start of any given layer, relative to the front\n",
    "    of the whole multilayer structure. (i.e. the start of layer 1)\n",
    "\n",
    "    d_list is list of thicknesses of layers [inf, blah, blah, ..., blah, inf]\n",
    "\n",
    "    \"\"\"\n",
    "    final_answer = zeros(len(d_list))\n",
    "    final_answer[0] = -inf\n",
    "    final_answer[1] = 0\n",
    "    for i in range(2,len(d_list)):\n",
    "        final_answer[i] = final_answer[i-1] + d_list[i-1]\n",
    "    return final_answer\n",
    "\n",
    "class absorp_analytic_fn:\n",
    "    \"\"\"\n",
    "    Absorption in a given layer is a pretty simple analytical function:\n",
    "    The sum of four exponentials.\n",
    "\n",
    "    a(z) = A1*exp(a1*z) + A2*exp(-a1*z)\n",
    "           + A3*exp(1j*a3*z) + conj(A3)*exp(-1j*a3*z)\n",
    "\n",
    "    where a(z) is absorption at depth z, with z=0 being the start of the layer,\n",
    "    and A1,A2,a1,a3 are real numbers, with a1>0, a3>0, and A3 is complex.\n",
    "    The class stores these five parameters, as well as d, the layer thickness.\n",
    "    \n",
    "    This gives absorption as a fraction of intensity coming towards the first\n",
    "    layer of the stack.\n",
    "    \"\"\"\n",
    "    def fill_in(self, coh_tmm_data, layer):\n",
    "        \"\"\"\n",
    "        fill in the absorption analytic function starting from coh_tmm_data\n",
    "        (the output of coh_tmm), for absorption in the layer with index\n",
    "        \"layer\".\n",
    "        \"\"\"\n",
    "        pol = coh_tmm_data['pol']\n",
    "        v = coh_tmm_data['vw_list'][layer][0]\n",
    "        w = coh_tmm_data['vw_list'][layer][1]\n",
    "        kz = coh_tmm_data['kz_list'][layer]\n",
    "        n = coh_tmm_data['n_list'][layer]\n",
    "        n_0 = coh_tmm_data['n_list'][0]\n",
    "        th_0 = coh_tmm_data['th_0']\n",
    "        th = coh_tmm_data['th_list'][layer]\n",
    "        self.d = coh_tmm_data['d_list'][layer]\n",
    "\n",
    "        self.a1 = 2*kz.imag\n",
    "        self.a3 = 2*kz.real\n",
    "\n",
    "        if pol=='s':\n",
    "            temp = (n*cos(th)*kz).imag / (n_0*cos(th_0)).real\n",
    "            self.A1 = temp * abs(w)**2\n",
    "            self.A2 = temp * abs(v)**2\n",
    "            self.A3 = temp * v * conj(w)\n",
    "        else: # pol=='p'\n",
    "            temp = (2*(kz.imag)*(n*cos(conj(th))).real /\n",
    "                    (n_0*conj(cos(th_0))).real)\n",
    "            self.A1 = temp * abs(w)**2\n",
    "            self.A2 = temp * abs(v)**2\n",
    "            self.A3 = v * conj(w) * (-2*(kz.real)*(n*cos(conj(th))).imag /\n",
    "                (n_0*conj(cos(th_0))).real)\n",
    "        return self\n",
    "    \n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        Create copy of an absorp_analytic_fn object\n",
    "        \"\"\"\n",
    "        a = absorp_analytic_fn()\n",
    "        (a.A1, a.A2, a.A3, a.a1, a.a3, a.d) = (\n",
    "           self.A1, self.A2, self.A3, self.a1, self.a3, self.d)\n",
    "        return a\n",
    "    \n",
    "    def run(self,z):\n",
    "        \"\"\"\n",
    "        Calculates absorption at a given depth z, where z=0 is the start of the\n",
    "        layer.\n",
    "        \"\"\"\n",
    "        return (self.A1*exp(self.a1 * z) + self.A2*exp(-self.a1 * z)\n",
    "             + self.A3*exp(1j*self.a3*z) + conj(self.A3)*exp(-1j*self.a3*z))\n",
    "    \n",
    "    def flip(self):\n",
    "        \"\"\"\n",
    "        Flip the function front-to-back, to describe a(d-z) instead of a(z),\n",
    "        where d is layer thickness.\n",
    "        \"\"\"\n",
    "        newA1 = self.A2*exp(-self.a1 * self.d)\n",
    "        newA2 = self.A1*exp(self.a1 * self.d)\n",
    "        self.A1, self.A2 = newA1, newA2\n",
    "        self.A3 = conj(self.A3 * exp(1j * self.a3 * self.d))\n",
    "        return self\n",
    "        \n",
    "    def scale(self, factor):\n",
    "        \"\"\"\n",
    "        multiplies the absorption at each point by \"factor\".\n",
    "        \"\"\"\n",
    "        self.A1 *= factor\n",
    "        self.A2 *= factor\n",
    "        self.A3 *= factor\n",
    "        return self\n",
    "    \n",
    "    def add(self, b):\n",
    "        \"\"\"\n",
    "        adds another compatible absorption analytical function\n",
    "        \"\"\"\n",
    "        if (b.a1 != self.a1) or (b.a3 != self.a3):\n",
    "            raise ValueError('Incompatible absorption analytical functions!')\n",
    "        self.A1 += b.A1\n",
    "        self.A2 += b.A2\n",
    "        self.A3 += b.A3\n",
    "        return self\n",
    "\n",
    "def absorp_in_each_layer(coh_tmm_data):\n",
    "    \"\"\"\n",
    "    An array listing what proportion of light is absorbed in each layer.\n",
    "\n",
    "    Assumes the final layer eventually absorbs all transmitted light.\n",
    "\n",
    "    Assumes the initial layer eventually absorbs all reflected light.\n",
    "\n",
    "    Entries of array should sum to 1.\n",
    "\n",
    "    coh_tmm_data is output of coh_tmm()\n",
    "    \"\"\"\n",
    "    num_layers = len(coh_tmm_data['d_list'])\n",
    "    power_entering_each_layer = zeros(num_layers)\n",
    "    power_entering_each_layer[0] = 1\n",
    "    power_entering_each_layer[1] = coh_tmm_data['power_entering']\n",
    "    power_entering_each_layer[-1] = coh_tmm_data['T']\n",
    "    for i in range(2,num_layers-1):\n",
    "        power_entering_each_layer[i] = position_resolved(i,0,coh_tmm_data)['poyn']\n",
    "    final_answer = zeros(num_layers)\n",
    "    final_answer[0:-1] = -np.diff(power_entering_each_layer)\n",
    "    final_answer[-1] = power_entering_each_layer[-1]\n",
    "    return final_answer\n",
    "\n",
    "def inc_group_layers(n_list,d_list,c_list):\n",
    "    \"\"\"\n",
    "    Helper function for inc_tmm. Groups and sorts layer information.\n",
    "    \n",
    "    See coh_tmm for definitions of n_list, d_list.\n",
    "    \n",
    "    c_list is \"coherency list\". Each entry should be 'i' for incoherent or 'c'\n",
    "    for 'coherent'.\n",
    "    \n",
    "    A \"stack\" is a group of one or more consecutive coherent layers. A \"stack\n",
    "    index\" labels the stacks 0,1,2,.... The \"within-stack index\" counts the\n",
    "    coherent layers within the stack 1,2,3... [index 0 is the incoherent layer\n",
    "    before the stack starts]\n",
    "    \n",
    "    An \"incoherent layer index\" labels the incoherent layers 0,1,2,...\n",
    "    \n",
    "    An \"alllayer index\" labels all layers (all elements of d_list) 0,1,2,...\n",
    "    \n",
    "    Returns info about how the layers relate:\n",
    "    \n",
    "    * stack_d_list[i] = list of thicknesses of each coherent layer in the i'th\n",
    "      stack, plus starting and ending with \"inf\"\n",
    "    * stack_n_list[i] = list of refractive index of each coherent layer in the\n",
    "      i'th stack, plus the two surrounding incoherent layers\n",
    "    * all_from_inc[i] = j means that the layer with incoherent index i has\n",
    "      alllayer index j\n",
    "    * inc_from_all[i] = j means that the layer with alllayer index i has\n",
    "      incoherent index j. If j = nan then the layer is coherent.\n",
    "    * all_from_stack[i1][i2] = j means that the layer with stack index i1 and\n",
    "      within-stack index i2 has alllayer index j\n",
    "    * stack_from_all[i] = [j1 j2] means that the layer with alllayer index i is\n",
    "      part of stack j1 with withinstack-index j2. If stack_from_all[i] = nan\n",
    "      then the layer is incoherent\n",
    "    * inc_from_stack[i] = j means that the i'th stack comes after the layer\n",
    "      with incoherent index j, and before the layer with incoherent index j+1.\n",
    "    * stack_from_inc[i] = j means that the layer with incoherent index i comes\n",
    "      immediately after the j'th stack. If j=nan, it is not immediately\n",
    "      following a stack.\n",
    "    * num_stacks = number of stacks\n",
    "    * num_inc_layers = number of incoherent layers\n",
    "    * num_layers = number of layers total\n",
    "    \"\"\"\n",
    "\n",
    "    if (n_list.ndim != 1) or (d_list.ndim != 1):\n",
    "        raise ValueError(\"Problem with n_list or d_list!\")\n",
    "    if (d_list[0] != inf) or (d_list[-1] != inf):\n",
    "        raise ValueError('d_list must start and end with inf!')\n",
    "    if (c_list[0] != 'i') or (c_list[-1] != 'i'):\n",
    "        raise ValueError('c_list should start and end with \"i\"')\n",
    "    if not((n_list.size) == (d_list.size) == (len(c_list))):\n",
    "        raise ValueError('List sizes do not match!')\n",
    "    inc_index=0\n",
    "    stack_index=0\n",
    "    stack_d_list = []\n",
    "    stack_n_list = []\n",
    "    all_from_inc = []\n",
    "    inc_from_all = []\n",
    "    all_from_stack = []\n",
    "    stack_from_all = []\n",
    "    inc_from_stack = []\n",
    "    stack_from_inc = []\n",
    "    stack_in_progress = False\n",
    "    for alllayer_index in range(n_list.size):\n",
    "        if c_list[alllayer_index] == 'c': #coherent layer\n",
    "            inc_from_all.append(nan)\n",
    "            if not stack_in_progress: #this layer is starting new stack\n",
    "                stack_in_progress = True\n",
    "                ongoing_stack_d_list = [inf,d_list[alllayer_index]]\n",
    "                ongoing_stack_n_list = [n_list[alllayer_index-1],\n",
    "                                        n_list[alllayer_index]]\n",
    "                stack_from_all.append([stack_index,1])\n",
    "                all_from_stack.append([alllayer_index-1,alllayer_index])\n",
    "                inc_from_stack.append(inc_index-1)\n",
    "                within_stack_index = 1\n",
    "                ###UP TO HERE\n",
    "            else: #another coherent layer in the same stack\n",
    "                ongoing_stack_d_list.append(d_list[alllayer_index])\n",
    "                ongoing_stack_n_list.append(n_list[alllayer_index])\n",
    "                within_stack_index += 1\n",
    "                stack_from_all.append([stack_index,within_stack_index])\n",
    "                all_from_stack[-1].append(alllayer_index)\n",
    "        elif c_list[alllayer_index] == 'i': #incoherent layer\n",
    "            stack_from_all.append(nan)\n",
    "            inc_from_all.append(inc_index)\n",
    "            all_from_inc.append(alllayer_index)\n",
    "            if not stack_in_progress: #previous layer was also incoherent\n",
    "                stack_from_inc.append(nan)\n",
    "            else: #previous layer was coherent\n",
    "                stack_in_progress = False\n",
    "                stack_from_inc.append(stack_index)\n",
    "                ongoing_stack_d_list.append(inf)\n",
    "                stack_d_list.append(ongoing_stack_d_list)\n",
    "                ongoing_stack_n_list.append(n_list[alllayer_index])\n",
    "                stack_n_list.append(ongoing_stack_n_list)\n",
    "                all_from_stack[-1].append(alllayer_index)\n",
    "                stack_index += 1\n",
    "            inc_index += 1\n",
    "        else:\n",
    "            raise ValueError(\"Error: c_list entries must be 'i' or 'c'!\")\n",
    "    return {'stack_d_list':stack_d_list,\n",
    "            'stack_n_list':stack_n_list,\n",
    "            'all_from_inc':all_from_inc,\n",
    "            'inc_from_all':inc_from_all,\n",
    "            'all_from_stack':all_from_stack,\n",
    "            'stack_from_all':stack_from_all,\n",
    "            'inc_from_stack':inc_from_stack,\n",
    "            'stack_from_inc':stack_from_inc,\n",
    "            'num_stacks':len(all_from_stack),\n",
    "            'num_inc_layers':len(all_from_inc),\n",
    "            'num_layers':len(n_list)}\n",
    "\n",
    "def inc_tmm(pol,n_list,d_list,c_list,th_0,lam_vac):\n",
    "    \"\"\"\n",
    "    Incoherent, or partly-incoherent-partly-coherent, transfer matrix method.\n",
    "    \n",
    "    See coh_tmm for definitions of pol, n_list, d_list, th_0, lam_vac.\n",
    "    \n",
    "    c_list is \"coherency list\". Each entry should be 'i' for incoherent or 'c'\n",
    "    for 'coherent'.\n",
    "    \n",
    "    If an incoherent layer has real refractive index (no absorption), then its\n",
    "    thickness doesn't affect the calculation results.\n",
    "    \n",
    "    See manual for details.\n",
    "    \n",
    "    Outputs the following as a dictionary (see manual for details):\n",
    "\n",
    "    * R--reflected wave power (as fraction of incident)\n",
    "    * T--transmitted wave power (as fraction of incident)\n",
    "    * VW_list-- n'th element is [V_n,W_n], the forward- and backward-traveling\n",
    "      intensities, respectively, at the beginning of the n'th incoherent medium.\n",
    "    * coh_tmm_data_list--n'th element is coh_tmm_data[n], the output of\n",
    "      the coh_tmm program for the n'th \"stack\" (group of one or more\n",
    "      consecutive coherent layers).\n",
    "    * coh_tmm_bdata_list--n'th element is coh_tmm_bdata[n], the output of the\n",
    "      coh_tmm program for the n'th stack, but with the layers of the stack\n",
    "      in reverse order.\n",
    "    * stackFB_list--n'th element is [F,B], where F is light traveling forward\n",
    "      towards the n'th stack and B is light traveling backwards towards the n'th\n",
    "      stack.    \n",
    "    * num_layers-- total number both coherent and incoherent.\n",
    "    * power_entering_list--n'th element is the normalized Poynting vector\n",
    "      crossing the interface into the n'th incoherent layer from the previous\n",
    "      (coherent or incoherent) layer.\n",
    "    * Plus, all the outputs of inc_group_layers\n",
    "\n",
    "    \"\"\"\n",
    "    #convert lists to numpy arrays if they're not already.\n",
    "    n_list=array(n_list)\n",
    "    d_list=array(d_list,dtype=float)\n",
    "\n",
    "    #input tests\n",
    "    if (np.real_if_close(n_list[0]*np.sin(th_0))).imag != 0:\n",
    "        raise ValueError('Error in n0 or th0!')\n",
    "    \n",
    "    group_layers_data = inc_group_layers(n_list,d_list,c_list)\n",
    "    num_inc_layers = group_layers_data['num_inc_layers']\n",
    "    num_stacks = group_layers_data['num_stacks']\n",
    "    stack_n_list = group_layers_data['stack_n_list']\n",
    "    stack_d_list = group_layers_data['stack_d_list']\n",
    "    all_from_stack = group_layers_data['all_from_stack']\n",
    "    all_from_inc = group_layers_data['all_from_inc']\n",
    "    all_from_stack = group_layers_data['all_from_stack']\n",
    "    stack_from_inc = group_layers_data['stack_from_inc']\n",
    "    inc_from_stack = group_layers_data['inc_from_stack']\n",
    "    \n",
    "    #th_list is a list with, for each layer, the angle that the light travels\n",
    "    #through the layer. Computed with Snell's law. Note that the \"angles\" may be\n",
    "    #complex!\n",
    "    th_list = list_snell(n_list,th_0)\n",
    "    \n",
    "    #coh_tmm_data_list[i] is the output of coh_tmm for the i'th stack\n",
    "    coh_tmm_data_list = []\n",
    "    #coh_tmm_bdata_list[i] is the same stack as coh_tmm_data_list[i] but\n",
    "    #with order of layers reversed\n",
    "    coh_tmm_bdata_list = []\n",
    "    for i in range(num_stacks):\n",
    "        coh_tmm_data_list.append(coh_tmm(pol,stack_n_list[i],\n",
    "                                              stack_d_list[i],\n",
    "                                              th_list[all_from_stack[i][0]],\n",
    "                                              lam_vac))\n",
    "        coh_tmm_bdata_list.append(coh_tmm_reverse(pol,stack_n_list[i],\n",
    "                                              stack_d_list[i],\n",
    "                                              th_list[all_from_stack[i][0]],\n",
    "                                              lam_vac))\n",
    "    \n",
    "    #P_list[i] is fraction not absorbed in a single pass through i'th incoherent\n",
    "    #layer.\n",
    "    P_list = zeros(num_inc_layers)\n",
    "    for inc_index in range(1,num_inc_layers-1): #skip 0'th and last (infinite)\n",
    "        i = all_from_inc[inc_index]\n",
    "        P_list[inc_index] = exp(-4 * np.pi * d_list[i]\n",
    "                     * (n_list[i] * cos(th_list[i])).imag / lam_vac)\n",
    "        #For a very opaque layer, reset P to avoid divide-by-0 and similar\n",
    "        #errors.\n",
    "        if P_list[inc_index] < 1e-30:\n",
    "            P_list[inc_index] = 1e-30\n",
    "    #T_list[i,j] and R_list[i,j] are transmission and reflection powers,\n",
    "    #respectively, coming from the i'th incoherent layer, going to the j'th\n",
    "    #incoherent layer. Only need to calculate this when j=i+1 or j=i-1.\n",
    "    #(2D array is overkill but helps avoid confusion.)\n",
    "    #initialize these arrays\n",
    "    T_list = zeros((num_inc_layers,num_inc_layers))\n",
    "    R_list = zeros((num_inc_layers,num_inc_layers))\n",
    "    for inc_index in range(num_inc_layers-1): #looking at interface i -> i+1\n",
    "        alllayer_index = all_from_inc[inc_index]\n",
    "        nextstack_index = stack_from_inc[inc_index+1]\n",
    "        if isnan(nextstack_index): #next layer is incoherent\n",
    "            R_list[inc_index,inc_index+1] = (\n",
    "                   interface_R(pol,n_list[alllayer_index],\n",
    "                               n_list[alllayer_index+1],\n",
    "                               th_list[alllayer_index],\n",
    "                               th_list[alllayer_index+1]))\n",
    "            T_list[inc_index,inc_index+1] = (\n",
    "                   interface_T(pol,n_list[alllayer_index],\n",
    "                               n_list[alllayer_index+1],\n",
    "                               th_list[alllayer_index],\n",
    "                               th_list[alllayer_index+1]))\n",
    "            R_list[inc_index+1,inc_index] = (\n",
    "                   interface_R(pol,n_list[alllayer_index+1],\n",
    "                               n_list[alllayer_index],\n",
    "                               th_list[alllayer_index+1],\n",
    "                               th_list[alllayer_index]))\n",
    "            T_list[inc_index+1,inc_index] = (\n",
    "                   interface_T(pol,n_list[alllayer_index+1],\n",
    "                               n_list[alllayer_index],\n",
    "                               th_list[alllayer_index+1],\n",
    "                               th_list[alllayer_index]))\n",
    "        else: #next layer is coherent\n",
    "            R_list[inc_index,inc_index+1] = (\n",
    "                    coh_tmm_data_list[nextstack_index]['R'])\n",
    "            T_list[inc_index,inc_index+1] = (\n",
    "                    coh_tmm_data_list[nextstack_index]['T'])\n",
    "            R_list[inc_index+1,inc_index] = (\n",
    "                    coh_tmm_bdata_list[nextstack_index]['R'])\n",
    "            T_list[inc_index+1,inc_index] = (\n",
    "                    coh_tmm_bdata_list[nextstack_index]['T'])\n",
    "\n",
    "    #L is the transfer matrix from the i'th to (i+1)st incoherent layer, see\n",
    "    #manual\n",
    "    L_list = [nan] # L_0 is not defined because 0'th layer has no beginning.\n",
    "    Ltilde = (array([[1,-R_list[1,0]],\n",
    "                     [R_list[0,1],\n",
    "                      T_list[1,0]*T_list[0,1] - R_list[1,0]*R_list[0,1]]])\n",
    "                / T_list[0,1])\n",
    "    for i in range(1,num_inc_layers-1):\n",
    "        L = np.dot(\n",
    "           array([[1/P_list[i],0],[0,P_list[i]]]),\n",
    "           array([[1,-R_list[i+1,i]],\n",
    "                  [R_list[i,i+1],\n",
    "                   T_list[i+1,i]*T_list[i,i+1] - R_list[i+1,i]*R_list[i,i+1]]])\n",
    "           ) / T_list[i,i+1]\n",
    "        L_list.append(L)\n",
    "        Ltilde = np.dot(Ltilde,L)\n",
    "    T = 1 / Ltilde[0,0]\n",
    "    R = Ltilde[1,0] / Ltilde[0,0]\n",
    "\n",
    "    #VW_list[n] = [V_n, W_n], the forward- and backward-moving intensities\n",
    "    #at the beginning of the n'th incoherent layer. VW_list[0] is undefined\n",
    "    #because 0'th layer has no beginning.\n",
    "    VW_list=zeros((num_inc_layers,2))\n",
    "    VW_list[0,:] = [nan,nan]\n",
    "    VW = array([[T],[0]])\n",
    "    VW_list[-1,:] = np.transpose(VW)\n",
    "    for i in range(num_inc_layers-2,0,-1):\n",
    "        VW = np.dot(L_list[i], VW)\n",
    "        VW_list[i,:] = np.transpose(VW)\n",
    "    \n",
    "    #stackFB_list[n]=[F,B] means that F is light traveling forward towards n'th\n",
    "    #stack and B is light traveling backwards towards n'th stack.\n",
    "    #Reminder: inc_from_stack[i] = j means that the i'th stack comes after the\n",
    "    #layer with incoherent index j.\n",
    "    stackFB_list=[]\n",
    "    for stack_index, prev_inc_index in enumerate(inc_from_stack):\n",
    "        if prev_inc_index == 0: #stack starts right after semi-infinite layer.\n",
    "            F = 1\n",
    "        else:\n",
    "            F = VW_list[prev_inc_index][0] * P_list[prev_inc_index]\n",
    "        B = VW_list[prev_inc_index+1][1]\n",
    "        stackFB_list.append([F,B])\n",
    "    \n",
    "    #power_entering_list[i] is the normalized Poynting vector crossing the\n",
    "    #interface into the i'th incoherent layer from the previous (coherent or\n",
    "    #incoherent) layer. See manual.\n",
    "    power_entering_list=[1] #\"1\" by convention for infinite 0th layer.\n",
    "    for i in range(1,num_inc_layers):\n",
    "        prev_stack_index = stack_from_inc[i]\n",
    "        if isnan(prev_stack_index):\n",
    "            #case where this layer directly follows another incoherent layer\n",
    "            if i==1: #special case because VW_list[0] & A_list[0] are undefined\n",
    "                power_entering_list.append(T_list[0,1]\n",
    "                                            -VW_list[1][1]*T_list[1,0])\n",
    "            else:\n",
    "                power_entering_list.append(\n",
    "                    VW_list[i-1][0]*P_list[i-1]*T_list[i-1,i]\n",
    "                    - VW_list[i][1]*T_list[i,i-1])\n",
    "        else: #case where this layer follows a coherent stack\n",
    "            power_entering_list.append(\n",
    "                stackFB_list[prev_stack_index][0] *\n",
    "                 coh_tmm_data_list[prev_stack_index]['T']\n",
    "                - stackFB_list[prev_stack_index][1] *\n",
    "                 coh_tmm_bdata_list[prev_stack_index]['power_entering'])\n",
    "    ans = {'T':T, 'R':R, 'VW_list':VW_list,\n",
    "            'coh_tmm_data_list':coh_tmm_data_list,\n",
    "            'coh_tmm_bdata_list':coh_tmm_bdata_list,\n",
    "            'stackFB_list':stackFB_list,\n",
    "            'power_entering_list':power_entering_list}\n",
    "    ans.update(group_layers_data)\n",
    "    return ans\n",
    "\n",
    "def inc_absorp_in_each_layer(inc_data):\n",
    "    \"\"\"\n",
    "    A list saying what proportion of light is absorbed in each layer.\n",
    "    \n",
    "    Assumes all reflected light is eventually absorbed in the 0'th medium, and\n",
    "    all transmitted light is eventually absorbed in the final medium.\n",
    "    \n",
    "    Returns a list [layer0absorp, layer1absorp, ...]. Entries should sum to 1.\n",
    "    \n",
    "    inc_data is output of incoherent_main()\n",
    "    \"\"\"\n",
    "    #Reminder: inc_from_stack[i] = j means that the i'th stack comes after the\n",
    "    #layer with incoherent index j.\n",
    "    #Reminder: stack_from_inc[i] = j means that the layer\n",
    "    #with incoherent index i comes immediately after the j'th stack (or j=nan\n",
    "    #if it's not immediately following a stack).\n",
    "\n",
    "    stack_from_inc = inc_data['stack_from_inc']\n",
    "    power_entering_list = inc_data['power_entering_list']\n",
    "    #stackFB_list[n]=[F,B] means that F is light traveling forward towards n'th\n",
    "    #stack and B is light traveling backwards towards n'th stack.\n",
    "    stackFB_list = inc_data['stackFB_list']\n",
    "    absorp_list = []\n",
    "    \n",
    "    #loop through incoherent layers, excluding the final layer\n",
    "    for i,power_entering in enumerate(power_entering_list[:-1]):\n",
    "        if isnan(stack_from_inc[i+1]):\n",
    "            #case that incoher layer i is right before another incoherent layer\n",
    "            absorp_list.append(power_entering_list[i]-power_entering_list[i+1])\n",
    "        else: #incoherent layer i is immediately before a coherent stack\n",
    "            j = stack_from_inc[i+1]\n",
    "            coh_tmm_data = inc_data['coh_tmm_data_list'][j]\n",
    "            coh_tmm_bdata = inc_data['coh_tmm_bdata_list'][j]\n",
    "            #First, power in the incoherent layer...\n",
    "            power_exiting = (\n",
    "               stackFB_list[j][0] * coh_tmm_data['power_entering']\n",
    "                  - stackFB_list[j][1] * coh_tmm_bdata['T'])\n",
    "            absorp_list.append(power_entering_list[i]-power_exiting)\n",
    "            #Next, power in the coherent stack...\n",
    "            stack_absorp = ((stackFB_list[j][0] *\n",
    "                        absorp_in_each_layer(coh_tmm_data))[1:-1]\n",
    "                       + (stackFB_list[j][1] *\n",
    "                        absorp_in_each_layer(coh_tmm_bdata))[-2:0:-1])\n",
    "            absorp_list.extend(stack_absorp)\n",
    "    #final semi-infinite layer\n",
    "    absorp_list.append(inc_data['T'])\n",
    "    return absorp_list\n",
    "\n",
    "def inc_find_absorp_analytic_fn(layer, inc_data):\n",
    "    \"\"\"\n",
    "    Outputs an absorp_analytic_fn object for a coherent layer within a\n",
    "    partly-incoherent stack.\n",
    "    \n",
    "    inc_data is output of incoherent_main()\n",
    "    \"\"\"\n",
    "    j = inc_data['stack_from_all'][layer]\n",
    "    if isnan(j):\n",
    "        raise ValueError('layer must be coherent for this function!')\n",
    "    [stackindex, withinstackindex] = j\n",
    "    forwardfunc = absorp_analytic_fn()\n",
    "    forwardfunc.fill_in(inc_data['coh_tmm_data_list'][stackindex],\n",
    "                        withinstackindex)\n",
    "    forwardfunc.scale(inc_data['stackFB_list'][stackindex][0])\n",
    "    backfunc = absorp_analytic_fn()\n",
    "    backfunc.fill_in(inc_data['coh_tmm_bdata_list'][stackindex],\n",
    "               -1-withinstackindex)\n",
    "    backfunc.scale(inc_data['stackFB_list'][stackindex][1])\n",
    "    backfunc.flip()\n",
    "    return forwardfunc.add(backfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_2x2_array(a, b, c, d, dtype=complex):\n",
    "    \"\"\"\n",
    "    Makes a 2x2 numpy array of [[a,b],[c,d]]\n",
    "    \n",
    "    Same as \"numpy.array([[a,b],[c,d]], dtype=float)\", but ten times faster\n",
    "    \"\"\"\n",
    "    ac =np.concatenate((a[:,:,np.newaxis],c[:,:,np.newaxis]),axis=-1)\n",
    "    bd =np.concatenate((b[:,:,np.newaxis],d[:,:,np.newaxis]),axis=-1)\n",
    "    abcd =np.concatenate((ac[:,:,:,np.newaxis],bd[:,:,:,np.newaxis]),axis=-1)\n",
    "    return abcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "th_list = list_snell(n_list,th_0)\n",
    "kz_list = (2 * np.pi * my_array * np.cos(th_list)) / np.array(mat.index)[:, None]\n",
    "delta = kz_list * d_list\n",
    "M1 = make_2x2_array(exp(-1j*delta), np.zeros((n_wv, 3)), np.zeros((n_wv, 3)), exp(1j*delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = model.mat_df[['Air', 'SiO2', 'TCO']]\n",
    "d_list = [sp.inf, 120, sp.inf]\n",
    "theta = 55*sp.pi/180\n",
    "my_array = np.array(mat)\n",
    "th_list = list_snell(my_array, theta)\n",
    "#mine = coh_tmm('p', my_array, d_list, theta, np.array(mat.index))['t_list']\n",
    "mine = interface_r('s', my_array[:,0], my_array[:, 1], th_list[:, 0], th_list[:, 1])\n",
    "mine = pd.Series(mine, mat.index)\n",
    "tmm_series = pd.Series()\n",
    "for i in mat.index:\n",
    "    index_array = np.array(mat.loc[i])\n",
    "    tmm_th_list = tmm.list_snell(index_array, i)\n",
    "    values = tmm.interface_r('s', index_array[0], index_array[1], tmm_th_list[0], tmm_th_list[1])\n",
    "    #values = tmm.coh_tmm('p', index_array, d_list, theta, i)['t_list']\n",
    "    \n",
    "    tmm_series.loc[i] = values\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = model.mat_df[['Air', 'SiO2', 'TCO']]\n",
    "d_list = [sp.inf, 120, sp.inf]\n",
    "theta = 55*sp.pi/180\n",
    "my_array = np.array(mat)\n",
    "th_list = list_snell(my_array, theta)\n",
    "#mine = coh_tmm('p', my_array, d_list, theta, np.array(mat.index))['t_list']\n",
    "mine = interface_t('p', my_array[:,0], my_array[:, 1], th_list[:, 0], th_list[:, 1])\n",
    "mine = pd.Series(mine, mat.index)\n",
    "tmm_series = pd.Series()\n",
    "for i in mat.index:\n",
    "    index_array = np.array(mat.loc[i])\n",
    "    tmm_th_list = tmm.list_snell(index_array, theta)\n",
    "    values = tmm.interface_t('p', index_array[0], index_array[1], tmm_th_list[0], tmm_th_list[1])\n",
    "    #values = tmm.coh_tmm('p', index_array, d_list, theta, i)['t_list']\n",
    "    \n",
    "    tmm_series.loc[i] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = (my_array[:, 0]*np.cos(th_list[:,0]) - my_array[:, 1] * np.cos(th_list[:,1]))/(my_array[:, 0]*np.cos(th_list[:,0]) + my_array[:, 1] * np.cos(th_list[:,1]))\n",
    "mine = pd.Series(x, mat.index)\n",
    "tmm_series = pd.Series()\n",
    "test_cos = pd.Series()\n",
    "for i in mat.index:\n",
    "    index_array = np.array(mat.loc[i])\n",
    "    tmm_th_list = tmm.list_snell(index_array, theta)\n",
    "    test = np.cos(tmm_th_list[0])\n",
    "    values = (index_array[0]*np.cos(tmm_th_list[0]) - index_array[1] * np.cos(tmm_th_list[1]))/(index_array[0]*np.cos(tmm_th_list[0]) + index_array[1] * np.cos(tmm_th_list[1]))\n",
    "    tmm_series.loc[i] = values\n",
    "    test_cos.loc[i] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pol = 's'\n",
    "n_list = np.array(mat)\n",
    "d_list = [sp.inf, 120, sp.inf]\n",
    "th_0 = 55*sp.pi/180\n",
    "lam_vac = np.array(mat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_layers = n_list.shape[1]\n",
    "n_wv = n_list.shape[0]\n",
    "th_list = list_snell(n_list,th_0)\n",
    "kz_list = (2 * np.pi * n_list * np.cos(th_list)) / lam_vac[:, None]\n",
    "delta = kz_list * d_list\n",
    "t_list = np.zeros((n_wv,num_layers),dtype=complex)\n",
    "r_list = np.zeros((n_wv,num_layers),dtype=complex)\n",
    "for i in range(num_layers-1):\n",
    "    t_list[:, i] = interface_t(pol, n_list[:,i], n_list[:,i+1], th_list[:,i], th_list[:,i+1])\n",
    "    r_list[:, i] = interface_r(pol, n_list[:,i], n_list[:,i+1], th_list[:,i], th_list[:,i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 2, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mtilde = np.zeros((n_wv,2,2), dtype=complex)\n",
    "Mtilde[:] = np.identity(2, dtype=complex)\n",
    "for i in range(1,num_layers-1):\n",
    "    '''This is impossible to read'''\n",
    "    M_list = (1/t_list[:,i]).reshape(n_wv,1,1) * np.einsum('ijk,ikl->ijl',\n",
    "        np.array([[exp(-1j*delta[:,i]), np.zeros((n_wv))], [np.zeros((n_wv)), exp(1j*delta[:,i])]], dtype=complex).T,\n",
    "        np.array([[np.ones((n_wv)), r_list[:,i]], [r_list[:,i], np.ones((n_wv))]], dtype=complex).T\n",
    "    )\n",
    "    Mtilde = np.einsum('ijk,ikl->ijl',Mtilde,M_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[        nan       +nanj,         nan       +nanj],\n",
       "        [        nan       +nanj,         nan       +nanj]],\n",
       "\n",
       "       [[-1.05469819-0.03363592j,  0.05481606+0.01828244j],\n",
       "        [ 0.05535155+0.01659078j, -1.05523368-0.0012373j ]],\n",
       "\n",
       "       [[-1.05408355-0.04517751j,  0.05443570+0.01864127j],\n",
       "        [ 0.05534803+0.015727j  , -1.05499588+0.01080924j]],\n",
       "\n",
       "       ..., \n",
       "       [[        nan       +nanj,         nan       +nanj],\n",
       "        [        nan       +nanj,         nan       +nanj]],\n",
       "\n",
       "       [[        nan       +nanj,         nan       +nanj],\n",
       "        [        nan       +nanj,         nan       +nanj]],\n",
       "\n",
       "       [[        nan       +nanj,         nan       +nanj],\n",
       "        [        nan       +nanj,         nan       +nanj]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300          NaN\n",
       "301     0.001281\n",
       "302     0.001273\n",
       "303     0.001265\n",
       "304     0.001257\n",
       "305     0.001248\n",
       "306     0.001239\n",
       "307     0.001229\n",
       "308     0.001220\n",
       "309     0.001211\n",
       "310     0.001202\n",
       "311     0.001192\n",
       "312     0.001183\n",
       "313     0.001174\n",
       "314     0.001165\n",
       "315     0.001155\n",
       "316     0.001146\n",
       "317     0.001137\n",
       "318     0.001127\n",
       "319     0.001118\n",
       "320     0.001109\n",
       "321     0.001099\n",
       "322     0.001090\n",
       "323     0.001080\n",
       "324     0.001071\n",
       "325     0.001062\n",
       "326     0.001053\n",
       "327     0.001044\n",
       "328     0.001038\n",
       "329     0.001030\n",
       "          ...   \n",
       "1670    0.000102\n",
       "1671    0.000102\n",
       "1672    0.000102\n",
       "1673    0.000102\n",
       "1674    0.000101\n",
       "1675    0.000101\n",
       "1676    0.000101\n",
       "1677    0.000101\n",
       "1678    0.000101\n",
       "1679    0.000100\n",
       "1680    0.000100\n",
       "1681    0.000100\n",
       "1682    0.000100\n",
       "1683    0.000100\n",
       "1684    0.000100\n",
       "1685    0.000099\n",
       "1686    0.000099\n",
       "1687    0.000099\n",
       "1688         NaN\n",
       "1689         NaN\n",
       "1690         NaN\n",
       "1691         NaN\n",
       "1692         NaN\n",
       "1693         NaN\n",
       "1694         NaN\n",
       "1695         NaN\n",
       "1696         NaN\n",
       "1697         NaN\n",
       "1698         NaN\n",
       "1699         NaN\n",
       "Name: R, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tmm_pandas as tmm_pd\n",
    "mat.apply(tmm_pd.coh_tmm, axis=1, args=('p', d_list, th_0))\n",
    "pd.DataFrame(list(x.values), index=x.index)['R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
